# Dataset 
**Note1: For train, test, and evaluation of the models, you should put unzipped data in [**Noisy_Dataset_V1**](./Noisy_Dataset_V1),  [**Noisy_Dataset_V2**](./Noisy_Dataset_V2) and [**simulated_rirs**](./simulated_rirs).**

**Note2: For running the codes, it is necessary to unzip test_filenames.zip, valid_filenames.zip and train_filenames_v2.zip files in this [**folder**](../dataset)**

**Note3: For each specific dataset, it is necessary to create train_filenames_v2.csv, test_filenames.csv, and valid_filenames.csv based on the path of your dataset in this [**folder**](../dataset).**

This [**folder**](../dataset) contains the project dataset for Speech Enhancement **(SE)**.

Approximately 4.6 million mp3 files were gathered from a noiseless Persian language and noise dataset for this project. The creation of the noisy data involved using reverb data, the QUT dataset, and the noisy data received from the employer as the pure noise dataset. Reverb data includes the reverberation of rooms of various sizes, and the QUT dataset contains 5 different types of noise (home, cafe, street, etc.). To generate the SE dataset, we initially extracted the speech portions from a subset of the Common Voice dataset. This data represents the noise-free section of the DS-Fa-v03 dataset. Noise samples were generated by utilizing data from both the real QUT noise dataset and noise data created by the employer. The noise-free part of DS-Fa-v03 dataset with different SNRs from **-2** to **30** dB with **2** steps with QUT data, and from **6** to **20** dB with **2** steps and extra levels **0, 25, 30** dB, only for the train part, from with the employer-created noise was mixed. During training and evaluation, we enriched our dataset by convolving randomly reverb data with 50% of the train and test sections of the DS-Fa-v03 dataset. This dataset is named **DS-Fa-v03_reverbed**. To inform more about our dataset, please, see the Phase-3 report.

```
DS-Fa-v03
	├── -2dB 
	│   ├── common_voice_fa_18202356SPLITCAR-WINUPB-1SPLIT0dB.mp3
	│   ├── common_voice_fa_18202357SPLITCAFE-CAFE-1SPLIT0dB.mp3
	│   ├── common_voice_fa_18202375SPLITREVERB-CARPARK-2SPLIT0dB.mp3	 	 
	│   ├──    .
	│   ├──    .	 	 
	│   └── common_voice_fa_18202378SPLITCAFE-CAFE-1SPLIT0dB.mp3
	├── 0 dB 
	│   ├── common_voice_fa_18202356SPLITCAR-WINUPB-1SPLIT0dB.mp3
	│   ├── common_voice_fa_18202357SPLITCAFE-CAFE-1SPLIT0dB.mp3
	│   ├── common_voice_fa_18202375SPLITREVERB-CARPARK-2SPLIT0dB.mp3	 	 
	│   ├──    .
	│   ├──    .	 	 
	│   └── common_voice_fa_18202378SPLITCAFE-CAFE-1SPLIT0dB.mp3
        .
        .
        .
        .
	├── 30 dB 
	│   ├── common_voice_fa_18202356SPLITCAR-WINUPB-1SPLIT0dB.mp3
	│   ├── common_voice_fa_18202357SPLITCAFE-CAFE-1SPLIT0dB.mp3
	│   ├── common_voice_fa_18202375SPLITREVERB-CARPARK-2SPLIT0dB.mp3	 	 
	│   ├──    .
	│   ├──    .	 	 
	│   └── common_voice_fa_18202378SPLITCAFE-CAFE-1SPLIT0dB.mp3
	└── InfdB
	    ├── common_voice_fa_18202356SPLITCAR-WINUPB-1SPLIT0dB.mp3
	    ├── common_voice_fa_18202357SPLITCAFE-CAFE-1SPLIT0dB.mp3
	    ├── common_voice_fa_18202375SPLITREVERB-CARPARK-2SPLIT0dB.mp3	 	 
	    ├──    .
	    ├──    .	 	 
	    └── common_voice_fa_18202378SPLITCAFE-CAFE-1SPLIT0dB.mp3

```
### Data collection procedure

In this project,the CommonVoice Persian version 13 database has been used to build a proper VAD database in Persian language.
CommonVoice is an open source project started by Mozilla to collect speech data, where people can speak sentences.

```bibtex
@article{nezami2019shemo,
  title={ShEMO: a large-scale validated database for Persian speech emotion detection},
  author={Nezami, Omid Mohamad and Lou, Paria Jamshid and Karami, Mansoureh},
  journal={Language Resources and Evaluation},
  volume={53},
  number={1},
  pages={1--16},
  year={2019},
  publisher={Springer}
}
```